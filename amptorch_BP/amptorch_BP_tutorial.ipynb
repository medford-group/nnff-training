{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "coordinate-reality",
   "metadata": {},
   "source": [
    "# Training with AMPtorch\n",
    "\n",
    "Edited by N. Hu\n",
    "Medford Research Group at Georgia Tech\n",
    "06/25/2021\n",
    "\n",
    "This ipython notebook is based on the sample scripts provided by AMPtorch (`amptorch/example/`). It introduces basic components and functions of AMPtorch. \n",
    "\n",
    "## Preparation: Install AMPtorch with conda\n",
    "\n",
    "Please follow the instructions as shown in the github repo to install AMPtorch and its dependencies: <https://github.com/ulissigroup/amptorch/tree/MCSH_paper1_lmdb>\n",
    "\n",
    "## Training on CuCO with Symmetry Functions and BPNN\n",
    "\n",
    "This example follows the convention of atomistic neural network potentials as described in Behler, J. (2015). Constructing high-dimensional neural network potentials: A tutorial review. International Journal of Quantum Chemistry, 115(16), 1032–1050. https://doi.org/10.1002/qua.24890"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "collect-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from ase import Atoms\n",
    "from ase.calculators.emt import EMT\n",
    "\n",
    "from amptorch.ase_utils import AMPtorch\n",
    "from amptorch.trainer import AtomsTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-treasure",
   "metadata": {},
   "source": [
    "### Construct the training dataset\n",
    "\n",
    "As an example, we calculate the potential energy and forces for CuCO chemical system with the EMT calculator implemented in ase. \n",
    "\n",
    "This step should be replaced with training datasets that have information on:\n",
    "1. cell size\n",
    "2. periodic boundary conditions\n",
    "3. atomic positions\n",
    "4. potential energy\n",
    "5. forces, if doing force training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "alternative-starter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training images\n",
    "\n",
    "distances = np.linspace(2, 5, 100)\n",
    "images = []\n",
    "for dist in distances:\n",
    "    image = Atoms(\n",
    "        \"CuCO\",\n",
    "        [\n",
    "            (-dist * np.sin(0.65), dist * np.cos(0.65), 0),\n",
    "            (0, 0, 0),\n",
    "            (dist * np.sin(0.65), dist * np.cos(0.65), 0),\n",
    "        ],\n",
    "    )\n",
    "    image.set_cell([10, 10, 10])\n",
    "    image.wrap(pbc=True)\n",
    "    image.set_calculator(EMT())\n",
    "    images.append(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-arcade",
   "metadata": {},
   "source": [
    "### Define fingerprinting scheme\n",
    "\n",
    "Here we demonstrate with the conventional Symmetry function. In our group, we have developed another fingerprinting scheme called GMP. Learn more about GMP at <https://arxiv.org/abs/2102.02390?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%253A+arxiv%252FQSXk+%2528ExcitingAds%2521+cs+updates+on+arXiv.org%2529>\n",
    "\n",
    "A demo script for training with GMP is also included: \n",
    "https://github.com/ulissigroup/amptorch/tree/MCSH_paper1_lmdb/examples/GMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "permanent-picnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gs = {\n",
    "    \"default\": {\n",
    "        \"G2\": {\n",
    "            \"etas\": np.logspace(np.log10(0.05), np.log10(5.0), num=4),\n",
    "            \"rs_s\": [0],\n",
    "        },\n",
    "        \"G4\": {\"etas\": [0.005], \"zetas\": [1.0, 4.0], \"gammas\": [1.0, -1.0]},\n",
    "        \"cutoff\": 6,\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-cleaners",
   "metadata": {},
   "source": [
    "### Define the configuration for trainer object\n",
    "\n",
    "Detailed introductions and other specifications supported in trainer object can be found here under Section Usage/Configs: \n",
    "<https://github.com/ulissigroup/amptorch/tree/MCSH_paper1_lmdb>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "loving-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"model\": {\n",
    "        \"get_forces\": True,\n",
    "        \"num_layers\": 3,\n",
    "        \"num_nodes\": 5,\n",
    "        \"batchnorm\": False,\n",
    "    },\n",
    "    \"optim\": {\n",
    "        \"force_coefficient\": 0.04,\n",
    "        \"lr\": 1e-2,\n",
    "        \"batch_size\": 32,\n",
    "        \"epochs\": 10,\n",
    "        \"loss\": \"mse\",\n",
    "        \"metric\": \"mae\",\n",
    "        \"gpus\": 0,\n",
    "    },\n",
    "    \"dataset\": {\n",
    "        \"raw_data\": images,\n",
    "        \"fp_params\": Gs,\n",
    "        \"save_fps\": True,\n",
    "        \"scaling\": {\"type\": \"normalize\", \"range\": (0, 1)},\n",
    "        \"val_split\": 0,\n",
    "    },\n",
    "    \"cmd\": {\n",
    "        \"debug\": False,\n",
    "        \"run_dir\": \"./\",\n",
    "        \"seed\": 1,\n",
    "        \"identifier\": \"test\",\n",
    "        \"verbose\": True,\n",
    "        # Weights and Biases used for logging - an account(free) is required\n",
    "        \"logger\": False,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-hands",
   "metadata": {},
   "source": [
    "### Hit go and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acknowledged-recommendation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ./checkpoints/2021-06-25-14-15-53-test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc3821ca1db4ec1ae51b655cbfdb138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='converting ASE atoms collection to Data objects', style=P…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff1c3203dea47118203f9a88eb5c211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Scaling Feature data (normalize)', style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f0133b63bca495a9e6f3e9ec338a8e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Scaling Target data', style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading dataset: 100 images\n",
      "Loading model: 963 parameters\n",
      "Loading skorch trainer\n",
      "  epoch    train_energy_mae    train_forces_mae    train_loss    cp     dur\n",
      "-------  ------------------  ------------------  ------------  ----  ------\n",
      "      1              \u001b[36m0.6019\u001b[0m              \u001b[32m0.3522\u001b[0m        \u001b[35m0.4378\u001b[0m     +  0.0160\n",
      "      2              0.6040              \u001b[32m0.3353\u001b[0m        \u001b[35m0.4280\u001b[0m        0.0159\n",
      "      3              \u001b[36m0.5027\u001b[0m              \u001b[32m0.3252\u001b[0m        \u001b[35m0.3093\u001b[0m     +  0.0160\n",
      "      4              \u001b[36m0.4639\u001b[0m              \u001b[32m0.3194\u001b[0m        \u001b[35m0.2469\u001b[0m     +  0.0163\n",
      "      5              \u001b[36m0.4627\u001b[0m              \u001b[32m0.3167\u001b[0m        \u001b[35m0.2262\u001b[0m     +  0.0159\n",
      "      6              \u001b[36m0.4268\u001b[0m              \u001b[32m0.3018\u001b[0m        0.2792     +  0.0158\n",
      "      7              \u001b[36m0.3834\u001b[0m              \u001b[32m0.2814\u001b[0m        \u001b[35m0.1318\u001b[0m     +  0.0159\n",
      "      8              \u001b[36m0.3514\u001b[0m              \u001b[32m0.2607\u001b[0m        0.1458     +  0.0161\n",
      "      9              \u001b[36m0.2804\u001b[0m              \u001b[32m0.2340\u001b[0m        \u001b[35m0.0801\u001b[0m     +  0.0159\n",
      "     10              \u001b[36m0.2119\u001b[0m              \u001b[32m0.2126\u001b[0m        0.0960     +  0.0159\n",
      "Training completed in 0.18897771835327148s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.18897771835327148"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_num_threads(1)\n",
    "trainer = AtomsTrainer(config)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-gathering",
   "metadata": {},
   "source": [
    "### Use the neural network as an ase calculator to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "potential-kingston",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "896a43e4c8f342829532624856a48c0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Scaling Feature data (normalize)', style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Energy MSE: 0.07593011091772355\n",
      "Energy MAE: 0.1824281114474392\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb82b71da4e246b8b4c8f7b4c9fc7f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Scaling Feature data (normalize)', max=1.0, style=Progres…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11.364912033081055"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = trainer.predict(images)\n",
    "\n",
    "# assess errors\n",
    "\n",
    "true_energies = np.array([image.get_potential_energy() for image in images])\n",
    "pred_energies = np.array(predictions[\"energy\"])\n",
    "\n",
    "print(\"Energy MSE:\", np.mean((true_energies - pred_energies) ** 2))\n",
    "print(\"Energy MAE:\", np.mean(np.abs(true_energies - pred_energies)))\n",
    "\n",
    "image.set_calculator(AMPtorch(trainer))\n",
    "image.get_potential_energy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amptorch_MCSH",
   "language": "python",
   "name": "amptorch_mcsh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
